{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-10T11:46:34.305332Z",
     "start_time": "2023-10-10T11:46:34.303088Z"
    }
   },
   "outputs": [],
   "source": [
    "# To run these scripts you need have folder 'data' with sample images on the same level as main.ipynb\n",
    "# Students: Vladislav Gorokhov & Assan Kabayev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def svm(X, y):\n",
    "    n_samples, n_features = X.shape\n",
    "    lambda_parameter = 0.01\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    y_ = np.where(y <= 0, -1, 1)\n",
    "\n",
    "    weight = np.zeros(n_features)\n",
    "    bias = 0\n",
    "\n",
    "    for _ in range(1000):\n",
    "        for idx, x_i in enumerate(X):\n",
    "            condition = y_[idx] * (np.dot(x_i, weight) - bias) >= 1\n",
    "            if condition:\n",
    "                weight -= learning_rate * (2 * lambda_parameter * weight)\n",
    "            else:\n",
    "                weight -= learning_rate * (2 * lambda_parameter * weight - np.dot(x_i, y_[idx]))\n",
    "                bias -= learning_rate * y_[idx]\n",
    "    return weight, bias\n",
    "\n",
    "def predict_svm(X, weight, bias):\n",
    "    return np.sign(np.dot(X, weight) - bias)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40278791abda6c0f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def logistic_regression(X, y):\n",
    "    n_samples, n_features = X.shape\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0\n",
    "\n",
    "    for _ in range(1000):\n",
    "        linear_model = np.dot(X, weights) + bias\n",
    "        y_predicted = 1 / (1 + np.exp(-linear_model))\n",
    "\n",
    "        # gradients\n",
    "        dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "        db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "        \n",
    "        weights -= learning_rate * dw\n",
    "        bias -= learning_rate * db\n",
    "    return weights, bias\n",
    "        \n",
    "def predict_logistic_regression(X, weights, bias):\n",
    "    linear_model = np.dot(X, weights) + bias\n",
    "    y_predicted = 1 / (1 + np.exp(-linear_model))\n",
    "    y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "    return np.array(y_predicted_cls)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T11:23:29.979728Z",
     "start_time": "2023-10-10T11:23:29.948505Z"
    }
   },
   "id": "d7a19975908a614a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def svn_cross_validation(X, y, k):\n",
    "    n_samples = len(X)\n",
    "    fold_size = n_samples // k\n",
    "    accuracies = []\n",
    "\n",
    "    for fold in range(k):\n",
    "        # Split the data into training and validation sets\n",
    "        val_start = fold * fold_size\n",
    "        val_end = val_start + fold_size\n",
    "        val_indices = list(range(val_start, val_end))\n",
    "        train_indices = [i for i in range(n_samples) if i not in val_indices]\n",
    "\n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "        X_val = X[val_indices]\n",
    "        y_val = y[val_indices]\n",
    "\n",
    "        # train\n",
    "        w, b = svm(X_train, y_train)\n",
    "\n",
    "        val_predictions = predict_svm(X_val, w, b)\n",
    "\n",
    "        # Calculate accuracy for this fold\n",
    "        accuracy = accuracy_score(y_val, val_predictions)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # Calculate the average accuracy over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    return avg_accuracy\n",
    "\n",
    "def logistic_regression_cross_validation(X, y, k):\n",
    "    n_samples = len(X)\n",
    "    fold_size = n_samples // k\n",
    "    accuracies = []\n",
    "\n",
    "    for fold in range(k):\n",
    "        # Split the data into training and validation sets\n",
    "        val_start = fold * fold_size\n",
    "        val_end = val_start + fold_size\n",
    "        val_indices = list(range(val_start, val_end))\n",
    "        train_indices = [i for i in range(n_samples) if i not in val_indices]\n",
    "\n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "        X_val = X[val_indices]\n",
    "        y_val = y[val_indices]\n",
    "\n",
    "        # train\n",
    "        w, b = logistic_regression(X_train, y_train)\n",
    "\n",
    "        val_predictions = predict_logistic_regression(X_val, w, b)\n",
    "\n",
    "        # Calculate accuracy for this fold\n",
    "        accuracy = accuracy_score(y_val, val_predictions)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # Calculate the average accuracy over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    return avg_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T11:23:29.981324Z",
     "start_time": "2023-10-10T11:23:29.961118Z"
    }
   },
   "id": "494bc09bb431f0f0"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gram', 'sugarcane', 'Tobacco-plant', 'Lemon', 'rice', 'Pearl_millet(bajra)', 'cotton', 'Cucumber', 'chilli', 'Cherry', 'cardamom', 'tea', 'jowar', 'Olive-tree', 'wheat', 'vigna-radiati(Mung)', 'coconut', 'Fox_nut(Makhana)', 'almond', 'clove', 'Coffee-plant', 'mustard-oil', 'jute', 'banana', 'soyabean', 'papaya', 'pineapple', 'tomato', 'sunflower', 'maize']\n",
      "Average SVM Accuracy (5-Fold CV): 3.0303%\n",
      "Logistic Regression Accuracy: 3.0303%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_dir = 'data'\n",
    "\n",
    "# Define categories\n",
    "#get all file names from the folder\n",
    "categories = os.listdir(input_dir)\n",
    "categories.remove(\".DS_Store\") \n",
    "\n",
    "# Load the model\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# loop over the input images\n",
    "for category_idx, category in enumerate(categories):\n",
    "    for file in os.listdir(os.path.join(input_dir, category)):\n",
    "        if file == \".DS_Store\":\n",
    "            continue\n",
    "            \n",
    "        img_path = os.path.join(input_dir, category, file)\n",
    "        img = imread(img_path)\n",
    "        img = resize(img, (32, 32, 3))\n",
    "        data.append(img.flatten())\n",
    "        labels.append(category_idx)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the data into a training and testing set\n",
    "X_train , X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, shuffle=True, stratify=labels)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "avg_accuracy = svn_cross_validation(data, labels, 5)\n",
    "print(f\"SVM Accuracy: {avg_accuracy * 100:.4f}%\")\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "avg_accuracy = logistic_regression_cross_validation(data, labels, 5)\n",
    "print(f\"Logistic Regression Accuracy: {avg_accuracy * 100:.4f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T11:35:15.379714Z",
     "start_time": "2023-10-10T11:31:25.645390Z"
    }
   },
   "id": "967e56dc3eef5c3"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<__main__.SVM object at 0x164a61bd0>' (type <class '__main__.SVM'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m param_grid_svm \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m100\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlambda_param\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m0.001\u001B[39m, \u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m1\u001B[39m]}\n\u001B[1;32m     16\u001B[0m grid_search_svm \u001B[38;5;241m=\u001B[39m GridSearchCV(SVM(), param_grid\u001B[38;5;241m=\u001B[39mparam_grid_svm, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m---> 17\u001B[0m grid_search_svm\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# For Logistic Regression\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mLogisticRegression\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1149\u001B[0m     )\n\u001B[1;32m   1150\u001B[0m ):\n\u001B[0;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:812\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    809\u001B[0m cv_orig \u001B[38;5;241m=\u001B[39m check_cv(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv, y, classifier\u001B[38;5;241m=\u001B[39mis_classifier(estimator))\n\u001B[1;32m    810\u001B[0m n_splits \u001B[38;5;241m=\u001B[39m cv_orig\u001B[38;5;241m.\u001B[39mget_n_splits(X, y, groups)\n\u001B[0;32m--> 812\u001B[0m base_estimator \u001B[38;5;241m=\u001B[39m clone(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimator)\n\u001B[1;32m    814\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs, pre_dispatch\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_dispatch)\n\u001B[1;32m    816\u001B[0m fit_and_score_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\n\u001B[1;32m    817\u001B[0m     scorer\u001B[38;5;241m=\u001B[39mscorers,\n\u001B[1;32m    818\u001B[0m     fit_params\u001B[38;5;241m=\u001B[39mfit_params,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    824\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[1;32m    825\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:76\u001B[0m, in \u001B[0;36mclone\u001B[0;34m(estimator, safe)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(estimator, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__sklearn_clone__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misclass(estimator):\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m estimator\u001B[38;5;241m.\u001B[39m__sklearn_clone__()\n\u001B[0;32m---> 76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _clone_parametrized(estimator, safe\u001B[38;5;241m=\u001B[39msafe)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:97\u001B[0m, in \u001B[0;36m_clone_parametrized\u001B[0;34m(estimator, safe)\u001B[0m\n\u001B[1;32m     91\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m     92\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot clone object. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     93\u001B[0m                 \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou should provide an instance of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     94\u001B[0m                 \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscikit-learn estimator instead of a class.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     95\u001B[0m             )\n\u001B[1;32m     96\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 97\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m     98\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot clone object \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (type \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m): \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     99\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mit does not seem to be a scikit-learn \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    100\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mestimator as it does not implement a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    101\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mget_params\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m method.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mrepr\u001B[39m(estimator), \u001B[38;5;28mtype\u001B[39m(estimator))\n\u001B[1;32m    102\u001B[0m             )\n\u001B[1;32m    104\u001B[0m klass \u001B[38;5;241m=\u001B[39m estimator\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\n\u001B[1;32m    105\u001B[0m new_object_params \u001B[38;5;241m=\u001B[39m estimator\u001B[38;5;241m.\u001B[39mget_params(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mTypeError\u001B[0m: Cannot clone object '<__main__.SVM object at 0x164a61bd0>' (type <class '__main__.SVM'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# For SVM\n",
    "class SVM:\n",
    "    def __init__(self):\n",
    "        self.b = None\n",
    "        self.w = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.w, self.b = svm(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return predict_svm(X, self.w, self.b)\n",
    "\n",
    "param_grid_svm = {'C': [0.01, 0.1, 1, 10, 100], 'lambda_param': [0.001, 0.01, 0.1, 1]}\n",
    "grid_search_svm = GridSearchCV(SVM(), param_grid=param_grid_svm, cv=5)\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# For Logistic Regression\n",
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.b = None\n",
    "        self.w = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.w, self.b = logistic_regression(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return predict_logistic_regression(X, self.w, self.b)\n",
    "\n",
    "param_grid_lr = {'learning_rate': [0.0001, 0.001, 0.01, 0.1], 'n_iters': [1000, 2000, 5000]}\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(), param_grid=param_grid_lr, cv=5)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters for both models\n",
    "print(\"Best SVM Hyperparameters:\", grid_search_svm.best_params_)\n",
    "print(\"Best Logistic Regression Hyperparameters:\", grid_search_lr.best_params_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T11:39:49.277493Z",
     "start_time": "2023-10-10T11:39:49.216133Z"
    }
   },
   "id": "80702971fd317f05"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Train the SVM and Logistic Regression models with the best hyperparameters\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m best_svm \u001B[38;5;241m=\u001B[39m grid_search_svm\u001B[38;5;241m.\u001B[39mbest_estimator_\n\u001B[1;32m      3\u001B[0m best_lr \u001B[38;5;241m=\u001B[39m grid_search_lr\u001B[38;5;241m.\u001B[39mbest_estimator_\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Train and evaluate the models on the test set\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "# Train the SVM and Logistic Regression models with the best hyperparameters\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "best_lr = grid_search_lr.best_estimator_\n",
    "\n",
    "# Train and evaluate the models on the test set\n",
    "best_svm.fit(X_train, y_train)\n",
    "best_lr.fit(X_train, y_train)\n",
    "\n",
    "svm_test_predictions = best_svm.predict(X_test)\n",
    "lr_test_predictions = best_lr.predict(X_test)\n",
    "\n",
    "svm_test_accuracy = accuracy_score(y_test, svm_test_predictions)\n",
    "lr_test_accuracy = accuracy_score(y_test, lr_test_predictions)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {svm_test_accuracy * 100:.2f}%\")\n",
    "print(f\"Logistic Regression Test Accuracy: {lr_test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Compare the accuracies and explain the results\n",
    "if svm_test_accuracy > lr_test_accuracy:\n",
    "    print(\"SVM performs better.\")\n",
    "    # Provide an explanation for the better performance.\n",
    "else:\n",
    "    print(\"Logistic Regression performs better.\")\n",
    "    # Provide an explanation for the better performance.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T11:40:32.323086Z",
     "start_time": "2023-10-10T11:40:32.299789Z"
    }
   },
   "id": "2008fb834045878a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fdfc2f4933e25982"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
