{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-10T11:46:34.305332Z",
     "start_time": "2023-10-10T11:46:34.303088Z"
    }
   },
   "outputs": [],
   "source": [
    "# To run these scripts you need have folder 'data' with sample images on the same level as main.ipynb\n",
    "# Students: Vladislav Gorokhov & Assan Kabayev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def svm(X, y):\n",
    "    n_samples, n_features = X.shape\n",
    "    lambda_parameter = 0.01\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    y_ = np.where(y <= 0, -1, 1)\n",
    "\n",
    "    weight = np.zeros(n_features)\n",
    "    bias = 0\n",
    "\n",
    "    for _ in range(1000):\n",
    "        for idx, x_i in enumerate(X):\n",
    "            condition = y_[idx] * (np.dot(x_i, weight) - bias) >= 1\n",
    "            if condition:\n",
    "                weight -= learning_rate * (2 * lambda_parameter * weight)\n",
    "            else:\n",
    "                weight -= learning_rate * (2 * lambda_parameter * weight - np.dot(x_i, y_[idx]))\n",
    "                bias -= learning_rate * y_[idx]\n",
    "    return weight, bias\n",
    "\n",
    "def predict_svm(X, weight, bias):\n",
    "    return np.sign(np.dot(X, weight) - bias)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40278791abda6c0f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def logistic_regression(X, y):\n",
    "    n_samples, n_features = X.shape\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0\n",
    "\n",
    "    for _ in range(1000):\n",
    "        linear_model = np.dot(X, weights) + bias\n",
    "        y_predicted = 1 / (1 + np.exp(-linear_model))\n",
    "\n",
    "        # gradients\n",
    "        dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "        db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "        \n",
    "        weights -= learning_rate * dw\n",
    "        bias -= learning_rate * db\n",
    "    return weights, bias\n",
    "        \n",
    "def predict_logistic_regression(X, weights, bias):\n",
    "    linear_model = np.dot(X, weights) + bias\n",
    "    y_predicted = 1 / (1 + np.exp(-linear_model))\n",
    "    y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "    return np.array(y_predicted_cls)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T11:23:29.979728Z",
     "start_time": "2023-10-10T11:23:29.948505Z"
    }
   },
   "id": "d7a19975908a614a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def svn_cross_validation(X, y, k):\n",
    "    n_samples = len(X)\n",
    "    fold_size = n_samples // k\n",
    "    accuracies = []\n",
    "\n",
    "    for fold in range(k):\n",
    "        # Split the data into training and validation sets\n",
    "        val_start = fold * fold_size\n",
    "        val_end = val_start + fold_size\n",
    "        val_indices = list(range(val_start, val_end))\n",
    "        train_indices = [i for i in range(n_samples) if i not in val_indices]\n",
    "\n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "        X_val = X[val_indices]\n",
    "        y_val = y[val_indices]\n",
    "\n",
    "        # train\n",
    "        w, b = svm(X_train, y_train)\n",
    "\n",
    "        val_predictions = predict_svm(X_val, w, b)\n",
    "\n",
    "        # Calculate accuracy for this fold\n",
    "        accuracy = accuracy_score(y_val, val_predictions)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # Calculate the average accuracy over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    return avg_accuracy\n",
    "\n",
    "def logistic_regression_cross_validation(X, y, k):\n",
    "    n_samples = len(X)\n",
    "    fold_size = n_samples // k\n",
    "    accuracies = []\n",
    "\n",
    "    for fold in range(k):\n",
    "        # Split the data into training and validation sets\n",
    "        val_start = fold * fold_size\n",
    "        val_end = val_start + fold_size\n",
    "        val_indices = list(range(val_start, val_end))\n",
    "        train_indices = [i for i in range(n_samples) if i not in val_indices]\n",
    "\n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "        X_val = X[val_indices]\n",
    "        y_val = y[val_indices]\n",
    "\n",
    "        # train\n",
    "        w, b = logistic_regression(X_train, y_train)\n",
    "\n",
    "        val_predictions = predict_logistic_regression(X_val, w, b)\n",
    "\n",
    "        # Calculate accuracy for this fold\n",
    "        accuracy = accuracy_score(y_val, val_predictions)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # Calculate the average accuracy over all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    return avg_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T11:23:29.981324Z",
     "start_time": "2023-10-10T11:23:29.961118Z"
    }
   },
   "id": "494bc09bb431f0f0"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gram', 'sugarcane', 'Tobacco-plant', 'Lemon', 'rice', 'Pearl_millet(bajra)', 'cotton', 'Cucumber', 'chilli', 'Cherry', 'cardamom', 'tea', 'jowar', 'Olive-tree', 'wheat', 'vigna-radiati(Mung)', 'coconut', 'Fox_nut(Makhana)', 'almond', 'clove', 'Coffee-plant', 'mustard-oil', 'jute', 'banana', 'soyabean', 'papaya', 'pineapple', 'tomato', 'sunflower', 'maize']\n",
      "Average SVM Accuracy (5-Fold CV): 3.0303%\n",
      "Logistic Regression Accuracy: 3.0303%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_dir = 'data'\n",
    "\n",
    "# Define categories\n",
    "#get all file names from the folder\n",
    "categories = os.listdir(input_dir)\n",
    "categories.remove(\".DS_Store\") \n",
    "\n",
    "# Load the model\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# loop over the input images\n",
    "for category_idx, category in enumerate(categories):\n",
    "    for file in os.listdir(os.path.join(input_dir, category)):\n",
    "        if file == \".DS_Store\":\n",
    "            continue\n",
    "            \n",
    "        img_path = os.path.join(input_dir, category, file)\n",
    "        img = imread(img_path)\n",
    "        img = resize(img, (32, 32, 3))\n",
    "        data.append(img.flatten())\n",
    "        labels.append(category_idx)\n",
    "\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the data into a training and testing set\n",
    "X_train , X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, shuffle=True, stratify=labels)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "avg_accuracy = svn_cross_validation(data, labels, 5)\n",
    "print(f\"SVM Accuracy: {avg_accuracy * 100:.4f}%\")\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "avg_accuracy = logistic_regression_cross_validation(data, labels, 5)\n",
    "print(f\"Logistic Regression Accuracy: {avg_accuracy * 100:.4f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T11:35:15.379714Z",
     "start_time": "2023-10-10T11:31:25.645390Z"
    }
   },
   "id": "967e56dc3eef5c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# For SVM\n",
    "class SVM:\n",
    "    def __init__(self):\n",
    "        self.b = None\n",
    "        self.w = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.w, self.b = svm(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return predict_svm(X, self.w, self.b)\n",
    "\n",
    "param_grid_svm = {'C': [0.01, 0.1, 1, 10, 100], 'lambda_param': [0.001, 0.01, 0.1, 1]}\n",
    "grid_search_svm = GridSearchCV(SVM(), param_grid=param_grid_svm, cv=5)\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# For Logistic Regression\n",
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.b = None\n",
    "        self.w = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.w, self.b = logistic_regression(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return predict_logistic_regression(X, self.w, self.b)\n",
    "\n",
    "param_grid_lr = {'learning_rate': [0.0001, 0.001, 0.01, 0.1], 'n_iters': [1000, 2000, 5000]}\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(), param_grid=param_grid_lr, cv=5)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters for both models\n",
    "print(\"Best SVM Hyperparameters:\", grid_search_svm.best_params_)\n",
    "print(\"Best Logistic Regression Hyperparameters:\", grid_search_lr.best_params_)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80702971fd317f05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the SVM and Logistic Regression models with the best hyperparameters\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "best_lr = grid_search_lr.best_estimator_\n",
    "\n",
    "# Train and evaluate the models on the test set\n",
    "best_svm.fit(X_train, y_train)\n",
    "best_lr.fit(X_train, y_train)\n",
    "\n",
    "svm_test_predictions = best_svm.predict(X_test)\n",
    "lr_test_predictions = best_lr.predict(X_test)\n",
    "\n",
    "svm_test_accuracy = accuracy_score(y_test, svm_test_predictions)\n",
    "lr_test_accuracy = accuracy_score(y_test, lr_test_predictions)\n",
    "\n",
    "print(f\"SVM Test Accuracy: {svm_test_accuracy * 100:.2f}%\")\n",
    "print(f\"Logistic Regression Test Accuracy: {lr_test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Compare the accuracies and explain the results\n",
    "if svm_test_accuracy > lr_test_accuracy:\n",
    "    print(\"SVM performs better.\")\n",
    "    # Provide an explanation for the better performance.\n",
    "else:\n",
    "    print(\"Logistic Regression performs better.\")\n",
    "    # Provide an explanation for the better performance.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2008fb834045878a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fdfc2f4933e25982"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
